{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, json, pickle, time\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Some code to make it pickle files\n",
    "years = range(1880, 2011)\n",
    "data_dir = 'data/features_csv/validation/'\n",
    "data_all = pd.DataFrame()\n",
    "files = os.listdir(data_dir)\n",
    "num_files = len(files)\n",
    "x = 0\n",
    "for i in os.listdir(data_dir):\n",
    "  if 'csv' not in i:\n",
    "    continue\n",
    "  \n",
    "  sys.stdout.write(\"\\r {:.2f} %\".format(100*x/num_files))\n",
    "  sys.stdout.flush()\n",
    "  frame = pd.read_csv(os.path.join(data_dir,i), header = None)\n",
    "\n",
    "  data_all = data_all.append(frame, ignore_index=True)\n",
    "  x += 1\n",
    " \n",
    "data = data_all.values\n",
    "with open('../data/validation_512.pickle','wb') as f:\n",
    "  pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6309, 514)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/256_train.pickle','rb') as f:\n",
    "  train_data = pickle.load(f)\n",
    "  \n",
    "#with open('../data/test.pickle','rb') as f:\n",
    "#  test_data = pickle.load(f)\n",
    "  \n",
    "with open('data/256_validation.pickle','rb') as f:\n",
    "  validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain, ytrain = train_data[:,1:-1], train_data[:,-1]\n",
    "Xvalidation, yvalidation = validation_data[:,1:-1], validation_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.53066204e+00, 5.14027816e-02, 1.32250567e-02, 4.56507070e-01,\n",
       "       7.26045891e-01, 1.28280417e-01, 2.56119716e-02, 2.09911528e-01,\n",
       "       1.03420036e+00, 9.56364028e-01, 1.20645356e-01, 6.35285447e-03,\n",
       "       2.37642915e-01, 1.85482771e-01, 6.04625347e-01, 1.67816492e+00,\n",
       "       9.95088615e-01, 7.17660703e-01, 1.08147990e-01, 8.27619278e-01,\n",
       "       2.15604233e+00, 2.33462632e-01, 5.04887310e-01, 3.39756328e-01,\n",
       "       9.49469440e-03, 4.52922312e-03, 1.74971964e+00, 1.47275419e-01,\n",
       "       1.61020933e-03, 7.52074362e-01, 1.07641060e-02, 5.15234245e-01,\n",
       "       1.09267112e+00, 1.43472755e+00, 9.69655572e-01, 2.51229263e-02,\n",
       "       1.93526256e+00, 6.56361926e-02, 1.00172718e-01, 2.06189152e-01,\n",
       "       3.60483478e-01, 9.00159552e-02, 8.54724612e-02, 2.11587925e-01,\n",
       "       9.78757720e-02, 1.65500002e+00, 1.25067087e+00, 1.46429121e+00,\n",
       "       9.58540629e-02, 1.36638811e-01, 4.62270243e-01, 3.32366971e-01,\n",
       "       6.37116509e-01, 2.36540875e-01, 1.33387652e+00, 1.22529950e+00,\n",
       "       2.77150693e-01, 8.94544961e-01, 3.82868910e-01, 2.68607026e-02,\n",
       "       8.90877354e-02, 6.16300473e-02, 8.05709662e-03, 7.35509004e-01,\n",
       "       8.71195655e-01, 3.87371746e-02, 4.76131592e-02, 4.04857670e-01,\n",
       "       1.59097383e+00, 1.12754306e-01, 1.49843716e-01, 1.97289086e-02,\n",
       "       6.20640889e-02, 9.06114540e-02, 4.65735254e-04, 1.40691026e-02,\n",
       "       7.65861340e-03, 2.35344171e-01, 1.43609529e+00, 7.58111265e-01,\n",
       "       1.66235180e-01, 1.25778505e-01, 5.11617902e-02, 1.17260111e-01,\n",
       "       5.04268502e-01, 2.43300522e-01, 1.66108985e-02, 1.22064752e-03,\n",
       "       1.06786766e-02, 6.67311450e-02, 1.79227309e-01, 2.18681706e-02,\n",
       "       4.07507029e-01, 1.54508994e-01, 1.90408698e+00, 9.63160614e-02,\n",
       "       2.88214310e-04, 6.69161641e-01, 7.52376296e-01, 2.11932528e-01,\n",
       "       1.64157372e-01, 3.37088764e+00, 2.79853151e+00, 2.99065835e-01,\n",
       "       3.32286338e-01, 3.67633692e-01, 1.09615673e+00, 1.65151887e+00,\n",
       "       2.95802706e-02, 3.42589433e-01, 2.45174940e-01, 1.28436440e-01,\n",
       "       1.41962769e-01, 7.38330774e-02, 1.48309059e-01, 1.02031766e-01,\n",
       "       2.99131875e-01, 9.95521856e-01, 2.67601941e-01, 4.30411577e-02,\n",
       "       3.84687044e-01, 2.86131274e-03, 1.39537929e-01, 1.64605806e-02,\n",
       "       3.79303648e-01, 2.80147583e-01, 2.72182847e-02, 8.91471218e-01,\n",
       "       7.82058191e-01, 1.48497455e+00, 1.95370157e+00, 1.11468642e+00,\n",
       "       4.91503942e-01, 3.58935098e-01, 5.68585231e-01, 2.15460369e-01,\n",
       "       9.68672665e-02, 2.00306364e-03, 4.00716205e+00, 1.36865788e+00,\n",
       "       8.15710726e-02, 1.48343878e-01, 2.61052450e-01, 3.52078515e-02,\n",
       "       6.03158297e-01, 8.13225457e-01, 4.33812390e-01, 3.02717209e-02,\n",
       "       2.70182585e-01, 2.08219301e-01, 1.15629607e-01, 5.68879593e-02,\n",
       "       3.79268463e-02, 3.13225816e-01, 3.61390039e-02, 4.34435821e-02,\n",
       "       2.55478967e-01, 2.64055313e-01, 5.09862053e-01, 1.80076313e-01,\n",
       "       8.29320293e-01, 7.31073653e-02, 3.94966531e+00, 2.37236067e-02,\n",
       "       5.89687148e-02, 8.86469328e-04, 1.03652625e+00, 6.13118989e-02,\n",
       "       8.12484094e-01, 1.94021522e+00, 3.46036507e-02, 4.64383401e-02,\n",
       "       3.72706915e-03, 8.07671261e-02, 3.40082168e-02, 3.02864889e-01,\n",
       "       5.05755015e-02, 1.78120368e-01, 1.50790243e-01, 8.00963579e-01,\n",
       "       3.14260216e+00, 3.70680787e-01, 3.68440027e-01, 9.69665601e-02,\n",
       "       3.41113839e-02, 5.05388849e-01, 5.90921971e-02, 4.31242059e-01,\n",
       "       5.16980133e-03, 1.78786827e-02, 2.85434373e-01, 5.85235378e-01,\n",
       "       2.46031280e-01, 6.72975561e-01, 5.05613740e-02, 4.12120511e-02,\n",
       "       1.40156977e+00, 1.85476350e-01, 7.13167180e-01, 6.13225386e-02,\n",
       "       2.57278841e-01, 8.25686909e-02, 4.90347078e-03, 2.42373964e-01,\n",
       "       9.29401801e-01, 8.98113780e-01, 1.02477537e+00, 7.58314181e-02,\n",
       "       1.56991845e+00, 3.07601736e-01, 4.95433350e-01, 3.21523683e-01,\n",
       "       4.00457700e+00, 1.16944388e-01, 3.08462946e-01, 5.82953627e-01,\n",
       "       2.79746770e-02, 6.71009227e-01, 5.76278957e-01, 8.75514143e-01,\n",
       "       1.02088704e+00, 6.38097888e-01, 2.90250888e-01, 2.18087175e-01,\n",
       "       4.16846065e-01, 2.80957896e-02, 2.47033637e-01, 1.61885235e-01,\n",
       "       9.47496428e-02, 3.95197173e-02, 3.10147971e-01, 7.89797144e-02,\n",
       "       1.99437476e-01, 2.07435092e+00, 8.70348972e-01, 3.03088943e-02,\n",
       "       7.08554663e-01, 9.18785912e-01, 1.44240249e-01, 1.00649482e+00,\n",
       "       8.91570455e-01, 6.17947580e-01, 6.54221340e-01, 3.14405218e+00,\n",
       "       3.76025962e-03, 2.64191895e-02, 1.49823195e+00, 7.60558417e-02,\n",
       "       1.02275432e-02, 1.74132809e-03, 2.67179568e-01, 1.85403441e-02,\n",
       "       4.41514275e-01, 6.11336496e-01, 7.92130279e-02, 1.04490233e-02,\n",
       "       2.90693921e+00, 5.86552995e-01, 3.48904749e-02, 1.22342621e-01,\n",
       "       1.02936104e-01, 8.40978194e-01, 2.01101041e-01, 1.91479473e-02,\n",
       "       4.55966649e-02, 7.17088000e-01, 7.21993467e-01, 1.09751511e-01,\n",
       "       2.37236968e-01, 5.89329447e-03, 4.59569702e-02, 1.17612918e-02,\n",
       "       8.17488051e-01, 6.09629006e-01, 2.35776611e-01, 6.87404372e-02,\n",
       "       2.08855777e-02, 2.42910536e-01, 3.22986137e-01, 2.21744614e-01,\n",
       "       7.18271524e-02, 4.20493171e-01, 9.50797463e-01, 4.19926850e-02,\n",
       "       1.07030973e-01, 2.11572106e-01, 1.21192060e-01, 7.95896501e-01,\n",
       "       7.27607762e-01, 8.95468854e-01, 5.80870393e-01, 5.09906970e-01,\n",
       "       1.71899903e-01, 4.48034603e-01, 4.83436160e-03, 4.22610589e-02,\n",
       "       1.96009989e-03, 1.56104648e+00, 1.35691769e-01, 4.79206284e-03,\n",
       "       6.67078357e-02, 5.45745806e-02, 1.31807341e-01, 3.02119243e-02,\n",
       "       7.58636800e-02, 2.43718944e-01, 6.47285290e-01, 6.86514427e-01,\n",
       "       1.06418652e-01, 4.05766161e-01, 1.07683469e-02, 1.72304589e-01,\n",
       "       2.33354822e+00, 2.44502564e-03, 3.00000454e-01, 4.63540530e-02,\n",
       "       1.93590986e-02, 2.02601790e-01, 5.49269013e-01, 2.03485529e+00,\n",
       "       1.66148329e-01, 3.12797294e-02, 4.37394500e-01, 5.52624300e-01,\n",
       "       1.09070694e-02, 5.47179156e-01, 8.90865243e-02, 8.52376718e-01,\n",
       "       2.57931807e-02, 1.98055238e+00, 2.26743473e-01, 3.16151467e-02,\n",
       "       9.13777633e-01, 1.23941603e-01, 3.53544503e+00, 1.32707212e+00,\n",
       "       3.01218702e+00, 6.29946759e-02, 2.53610626e-02, 1.70673299e-01,\n",
       "       2.50400923e-02, 9.41691852e-01, 8.93108138e-01, 6.74214543e-02,\n",
       "       7.00566595e-01, 4.82225898e-02, 2.24953634e-01, 4.83556009e-01,\n",
       "       6.41014646e-01, 4.89367351e-02, 1.01951907e-01, 2.93868612e-01,\n",
       "       4.21499061e-01, 1.55507762e-02, 2.00493660e-01, 1.67202793e-03,\n",
       "       5.44110207e-02, 1.23531203e+00, 2.00684410e-01, 1.53054528e-01,\n",
       "       4.50245932e-02, 2.55312094e-01, 3.49892073e-01, 1.79393707e-02,\n",
       "       1.13884129e+00, 9.79644472e-02, 1.22747230e-01, 4.44405862e-01,\n",
       "       1.81301712e+00, 2.60488710e-02, 1.06143647e+00, 1.10589751e-01,\n",
       "       5.74962907e-01, 9.54174003e-01, 1.71212282e-01, 7.25581193e-01,\n",
       "       3.16304097e-01, 1.14466546e-01, 1.90648876e-01, 9.36260017e-02,\n",
       "       4.83005997e-01, 8.85288381e-01, 2.04690673e+00, 4.38780684e-02,\n",
       "       4.72995590e-01, 2.42304086e-01, 2.60206304e-01, 1.58725981e+00,\n",
       "       8.10976721e-01, 2.10505002e-02, 2.06047176e-02, 1.28696483e+00,\n",
       "       2.69389333e-01, 3.07058792e-01, 1.06302602e-01, 2.86210835e-02,\n",
       "       8.86179584e-02, 2.26204257e-01, 3.89478690e-02, 4.92540243e-01,\n",
       "       2.00875843e+00, 1.65397084e+00, 6.88869810e-01, 4.08817939e-01,\n",
       "       7.70554671e-03, 1.36443481e-01, 7.23082923e-02, 1.16917874e-01,\n",
       "       3.08039360e-01, 9.84643801e-01, 9.46586660e-02, 4.15972820e-02,\n",
       "       4.97342589e-01, 9.30473843e-02, 4.09026532e-02, 5.43509173e-01,\n",
       "       6.94774139e-03, 5.57763079e-01, 3.91919488e-01, 6.29920058e-02,\n",
       "       2.20478398e-01, 3.70213858e-02, 1.27959801e-01, 3.18534105e-03,\n",
       "       8.17163649e-01, 6.13465600e-01, 8.44858720e-03, 5.49484063e-01,\n",
       "       8.91652941e-02, 1.53259149e+00, 5.72397958e-01, 3.03355512e-01,\n",
       "       8.19788721e-01, 5.90232568e-01, 1.53073328e+00, 7.69822382e-01,\n",
       "       2.33305333e-03, 4.55481928e-01, 1.73475313e-01, 2.66377858e+00,\n",
       "       2.70203604e-02, 3.24867140e-02, 1.21528199e+00, 3.66338717e-01,\n",
       "       4.45055419e-02, 6.76253539e-01, 6.81625067e-01, 1.09681122e-02,\n",
       "       4.10346744e-01, 1.69677393e-01, 1.37020497e+00, 3.18883430e-01,\n",
       "       7.34497269e-01, 1.96824118e-01, 2.93198622e-01, 8.90613738e-01,\n",
       "       1.48092371e-02, 8.69398862e-01, 4.87708598e-01, 5.38367267e-02,\n",
       "       2.47750941e+00, 2.74250666e-02, 2.61002577e-01, 3.41743534e-02,\n",
       "       2.47257182e-02, 5.77664038e-02, 1.52213834e-01, 8.22171479e-01,\n",
       "       3.23124206e-01, 1.95034797e+00, 9.19223854e-02, 6.43874189e-01,\n",
       "       2.38921095e-01, 3.24806557e-02, 8.60454666e-02, 6.46661871e-02,\n",
       "       1.87965404e-01, 3.01854622e-01, 2.78311201e-02, 3.05552536e-01,\n",
       "       2.65208600e+00, 2.30881983e-01, 5.74055592e-02, 7.58708077e-01,\n",
       "       1.91606082e-01, 1.08291733e+00, 3.18915634e-04, 3.71471414e-01,\n",
       "       3.38286434e-03, 3.31617657e-01, 1.41561686e-01, 2.99047101e-01,\n",
       "       1.11723782e-01, 6.59315511e-01, 5.18125985e-02, 1.85021767e+00,\n",
       "       6.59352818e-01, 1.35407136e-01, 5.88905749e-01, 1.33857442e+00,\n",
       "       1.25533975e-01, 2.93166061e-01, 7.37166978e-01, 6.21612018e-01,\n",
       "       3.13521785e-01, 2.23483371e-02, 1.52495112e+00, 2.84047071e-02,\n",
       "       2.12319014e-01, 3.29987913e-02, 3.45488897e-01, 2.89110823e-03])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward feature selection\n",
    "---\n",
    "\n",
    "Let first try what they did in the exercises. So forward feature selection:\n",
    "Lets (as in the exercise) try to find 5 features that are \"good\" using a random sample of 10000.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numpy.random.seed(1)\n",
    "rnd_list = np.random.randint(0, train_data.shape[0],10000)\n",
    "rnd_trn, rnd_val = rnd_list[:8000], rnd_list[8000:]\n",
    "\n",
    "Xtrn, ytrn = Xtrain[rnd_trn], ytrain[rnd_trn]\n",
    "Xval, yval = Xtrain[rnd_val], ytrain[rnd_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146]\n",
      "[146, 102]\n",
      "[146, 102, 110]\n",
      "[146, 102, 110, 165]\n",
      "[146, 102, 110, 165, 177]\n",
      "Seconds to run: 79.99695777893066\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "good_features = []\n",
    "val_scores = []\n",
    "\n",
    "feature_list = list(range(Xtrain.shape[1]))\n",
    "\n",
    "for j in range(1,6):\n",
    "    scores = []\n",
    "    for i in feature_list:\n",
    "        feature_slice = good_features+[i]\n",
    "        X = Xtrn[:,feature_slice]\n",
    "        model = KNeighborsClassifier(n_neighbors=10)\n",
    "        model.fit(X, ytrn)\n",
    "        scores.append(1- model.score(Xval[:,feature_slice],yval))\n",
    "    \n",
    "    best_ind = np.argmin(scores)\n",
    "    best_feature = feature_list[best_ind]\n",
    "    \n",
    "    val_scores.append(scores[best_ind])\n",
    "    good_features.append(best_feature)\n",
    "    del feature_list[best_ind]\n",
    "    print(good_features)\n",
    "    \n",
    "print('Seconds to run: {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9755, 0.968, 0.967, 0.9635, 0.963]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "It seems that 5 features is not enough to get a proper score. maybe 10000 is also not enough to do this. \n",
    "Also the exercise data had 54 features, we have 256, so maybe crank up the number of features desired. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PCA\n",
    "\n",
    "Also to furter reduce the number of features, lets look at PCA\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca= PCA()\n",
    "pca.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8450310831930141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "        119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "        132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "        145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "        158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
       "        171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "        223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "        236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
       "        249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
       "        262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
       "        275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287,\n",
       "        288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300,\n",
       "        301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313,\n",
       "        314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326,\n",
       "        327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
       "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352,\n",
       "        353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
       "        366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
       "        379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
       "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
       "        405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
       "        418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430,\n",
       "        431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443,\n",
       "        444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456,\n",
       "        457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469,\n",
       "        470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482,\n",
       "        483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
       "        496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508,\n",
       "        509, 510, 511]),)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_.cumsum()[65])\n",
    "np.where(pca.explained_variance_ratio_.cumsum()> 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 85% of the variance in data can be expressed using only 44 principle components. This seems like a nice number.\n",
    "\n",
    "So lets transform the data and run a couple classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TXtrain = pca.transform(Xtrain)[:,:65]\n",
    "TXvalidation = pca.transform(Xvalidation)[:,:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23189094943731178"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K nearest neighbor classifier\n",
    "# Score is the mean accuracy\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(Xtrain,ytrain)\n",
    "knn.score(Xvalidation, yvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15596766524013314"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "# Score is the mean accuracy\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 10)\n",
    "rfc.fit(Xtrain, ytrain)\n",
    "rfc.score(Xvalidation,yvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2664447614518941"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A multilayer Preceptron\n",
    "# Score is the mean accuracy again\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier((200,150))\n",
    "mlp.fit(Xtrain, ytrain)\n",
    "mlp.score(Xvalidation,yvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11760976382944999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "# Score is the mean accuracy\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(Xtrain,ytrain)\n",
    "gnb.score(Xvalidation,yvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
